---
title: "Cooling Center Optimization Utilizing Python SPOPT Library"
output: html_notebook
---

This R-notebook will go through the process of replicating the cooling center optimization in ArcPro using R. Being able to replicate the process in an open source software will enable greater access to the approach be eliminating licensing costs. Additionally, this code will serve as the base for the R-Shiny app which will allow me to present the optimization in an web based interface that decision makers can use directly. 

There seem to be a handful of open source coding libraries I can use to replicate the location modeling I conducted in ArcPro. For now I'm going to attempt two different approaches using a subset of the data I've used in ArcPro. The first approach uses the Maxcovr package in R. The second approach is to use functions in the Pysal libraries in Python. The second approach could be a bit more robust especially with location modeling using a network. However, both tools have been used in the context of a road network. Both approaches use solvers to identify the optimized set of locations to meet demand. For now I'm testing both approaches but in the design of the dashboard I will lean on one approach. 


```{r Setup Python Virtual Environment}
library(tidyverse)
library(reticulate)

## Reticulate to start up your virtual python environment
vrt.env <- "rpython-virtualenv-coolingcenteropt"
use_virtualenv("rpython-virtualenv-coolingcenteropt")
## Install python libraries into virtual environment
python.packages <- c("scipy","spopt","geopandas","pulp","shapely","spaghetti")
virtualenv_install(vrt.env, python.packages)

```

#### Input Data

For the time being, I'm going to read in the facility and demand point data which will be used to calculate the OD matrix which informs the optimization approach. I'm doing some minor editing of the input data to strip away PII and to merge the data into one data frame.
```{r Input_data}

library(dplyr)
library(sf)

candidatefac.file <- "../data/CoolingCenterDashboard-testdata/final_candidate_sites2024PhxUrbanCoresub.shp"
coolingfac.file <- "../data/CoolingCenterDashboard-testdata/Grp18_RespiteCoolingCenters2024_PhxUrbanCoreSub.shp"
homelessdmn.file <- "../data/CoolingCenterDashboard-testdata/Homeless_Outreach_PhxUrbanCoreSub.shp"
residentialdmn.file <- "../data/CoolingCenterDashboard-testdata/Residential_Parcel_Sample_PhxUrbanCoreSub.shp"

candidate.fac <- st_read(candidatefac.file)
cooling.fac <- st_read(coolingfac.file)
homeless.dmn <- st_read(homelessdmn.file)
residential.dmn <- st_read(residentialdmn.file)



```

#### Maxcovr Approach 

Maxcovr contains several functions that can be useful for location modeling.This includes the maxcovr function itself which, is the function to compute the MCLP. By default maxcovr calculates euclidean distance, which is not helpful for modeling travel along a network. However, the maxcovr function has options to input a distance matrix built on network distances. Additionally, this funciton has been used in this context before. I just need to be careful regarding the use of other functions because many calculate distance from lat lon coordinates. 

With this approach the maxcovr function is used through an optimization solver to identify the optimal solution. In order to run maxcovr we need to calculate the origin-destination (OD) distance matrix for every facility and demand point in our analysis. We are particularly interested in identifying the shortest distances from demand points to facilities. Maxcovr function will use this distance matrix to identify the optimal solution.

##### General Steps
1. Read in demand, facility, and road network data
2. Clean data
3. Calculate OD distance matrix between facilities and demand. Ensure network distances are used
4. Run Maxcovr 
5. Review Results

```{r maxcovr-approach}
library(maxcovr)
library(dplyr)
library(sf)


```


#### SPOPT Python Code
```{r}

```

